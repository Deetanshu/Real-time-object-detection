# Real time object detection
With the advent of video camera surveillance, the statement â€œBig brother is watching youâ€ seemed quite apt. Video cameras were deployed across the world, and at first, humans were tasked with watching the feeds. However, a human can hardly be expected to monitor every detail in the stream that so many video cameras relayed.
Similarly, in the 2000s, just searching for websites wasnâ€™t nearly enough. When one required an image, one couldnâ€™t simply search for the keywords of the image and expect viable results from a search engine. Yet, it was something of a need. Hence, computer vision gained footing. Fast forward to today, and we have Amazon Go, a supermarket where there are no cashiers, no checkout counters. With computer vision, Amazon tracks every item thatâ€™s placed in the customerâ€™s bag. This saves time for the customer, and Amazon doesnâ€™t have to hire cashiers and build cash counters in their upcoming supermarkets.
Hence, tasking a computer program to make accurate predictions on what an object in a picture was became an excellent problem statement. The traditional approach to this problem taken by the computer vision research community was to hand-craft functions which would look for particular features in the image that were believed to be indicative of certain objects or scenes. For example, hard corners and straight edges might be believed to indicate the presence of manmade objects in the scene. The responses from these feature extraction functions would then be fed into another function which would decide whether to declare a particular object had been detected in the image.
Figure 1: Traditional approach to machine perception: hand-crafted features are extracted from the raw data and is then independently passed to a classification function. This would typically lead to lower accuracy predictions, not to mention hand crafting took time.
Unfortunately, there are a number of problems with this approach. Firstly, it is very hard to think of robust, reliable features which map to specific object types. Secondly, it is a massive task to come up with the right combination of features for every type of object one would want to be able to classify. Thirdly, it is very difficult to design functions that are robust to the translations, rotations and scaling of objects in the image. Together these problems resulted in traditional computer vision struggling to develop high accuracy object detectors and classifiers for a broad range of objects.
Hence, Deep Neural Networks came into the picture. No human knowledge is encoded in the Deep Learning model about the types and combinations of features that are important for labelling different types of object or scene. Instead, a combined feature extraction and classification model was learned by allowing the computer to examine millions of labelled images to discover which features and combinations of features were most discriminative for each of the object classes, and this process is called training the model. Furthermore, this is done in such a way that the model doesn't just learn to classify the specific objects it is trained on; instead, it abstracts out the essence of those objects in such a way that it can recognize previously unseen but visually similar objects. This learning process refined tens of millions of free parameters in Deep Learning models enabling many to be able to accurately classify over 22,000 different object types (ImageNetâ€™s competition). The only down-side to this approach, one could say, would be that a lot of data is required to train a model to be accurate enough for the predictions of the model to be relied on, and on a traditional CPU based server this training would take weeks to complete. Networks these days are instead trained in just hours by exploiting GPU acceleration. Almost all Deep Learning Systems now are
trainable in practical amounts of time now. Below is an image depicting how Deep Learning works:
Figure 2: In the Deep Learning approach the feature extraction and classification functions are simultaneously learned using large amounts of training data. The learned model can then be deployed in a new application where previously unseen data samples are classified.
In the field of object detection in particular, a type of Artificial Neural Networks has shown great promise and great results. These are Convolutional Neural Networks(CNNs). They are comprised of one or more convolutional layers and have other layers such as fully connected layers to supplement them, making multilayered Neural Networks. Since images are essentially two dimensional in structure, CNNs are designed to take advantage of it. A convolutional layer takes an image (ğ‘¤Ã—ğ‘¤Ã—ğ‘ matrix where height and width are the same, and c is the number of channels) and the convolution filter or kernel is a smaller â€œimageâ€ (an ğ‘›Ã—ğ‘›Ã—ğ‘Ÿ matrix) where n is the height and width of the matrix and ğ‘Ÿâ‰¤ğ‘ is the number of channels (RGB in this application)
